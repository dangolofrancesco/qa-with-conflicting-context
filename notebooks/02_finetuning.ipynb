{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223ca85a",
   "metadata": {},
   "source": [
    "## Task 2: Finetuning Notebook\n",
    "Goal: To use the authors' training script to create our two finetuned models:\n",
    "- Model A: flan-t5-base finetuned on train_context_only.jsonl.\n",
    "- Model B: flan-t5-base finetuned on train_exp_ans.jsonl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d89189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autotrain-advanced\n",
      "  Downloading autotrain_advanced-0.8.36-py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.3/341.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting albumentations==1.4.23\n",
      "  Downloading albumentations-1.4.23-py3-none-any.whl (269 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.9/269.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets[vision]~=3.2.0\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate==0.4.3\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipadic==1.0.0\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jiwer==3.0.5\n",
      "  Downloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n",
      "Collecting joblib==1.4.2\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting loguru==0.7.3\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas==2.2.3\n",
      "  Using cached pandas-2.2.3-cp311-cp311-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "Collecting nltk==3.9.1\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting optuna==4.1.0\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Pillow==11.0.0\n",
      "  Using cached pillow-11.0.0-cp311-cp311-macosx_10_10_x86_64.whl (3.2 MB)\n",
      "Collecting sacremoses==0.1.1\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==1.6.0\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece==0.2.0\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm==4.67.1\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting werkzeug==3.1.3\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting xgboost==2.1.3\n",
      "  Using cached xgboost-2.1.3-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (2.1 MB)\n",
      "Collecting huggingface-hub==0.27.0\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests==2.32.3\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting einops==0.8.0\n",
      "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging==24.2\n",
      "  Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Collecting cryptography==44.0.0\n",
      "  Downloading cryptography-44.0.0-cp39-abi3-macosx_10_9_universal2.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvitop==1.3.2\n",
      "  Downloading nvitop-1.3.2-py3-none-any.whl (215 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.4/215.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard==2.18.0\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting peft==0.14.0\n",
      "  Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting trl==0.13.0\n",
      "  Downloading trl-0.13.0-py3-none-any.whl (293 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken==0.8.0\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.48.0\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting accelerate==1.2.1\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge-score==0.1.2\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py7zr==0.22.0\n",
      "  Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi==0.115.6\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn==0.34.0\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m498.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart==0.0.20\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Collecting pydantic==2.10.4\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.8/431.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hf-transfer\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-macosx_10_12_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyngrok==7.2.1\n",
      "  Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
      "Collecting authlib==1.4.0\n",
      "  Downloading Authlib-1.4.0-py2.py3-none-any.whl (225 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.5/225.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting itsdangerous==2.2.0\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Collecting seqeval==1.2.2\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httpx==0.28.1\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting pyyaml==6.0.2\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl (184 kB)\n",
      "Collecting timm==1.0.12\n",
      "  Downloading timm-1.0.12-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics==1.6.0\n",
      "  Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pycocotools==2.0.8\n",
      "  Downloading pycocotools-2.0.8-cp311-cp311-macosx_10_9_universal2.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.9/162.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentence-transformers==3.3.1\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate==1.2.1->autotrain-advanced) (1.24.4)\n",
      "Requirement already satisfied: psutil in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate==1.2.1->autotrain-advanced) (7.1.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate==1.2.1->autotrain-advanced) (2.2.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate==1.2.1->autotrain-advanced) (0.6.2)\n",
      "Collecting scipy>=1.10.0\n",
      "  Downloading scipy-1.16.3-cp311-cp311-macosx_14_0_x86_64.whl (23.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting albucore==0.0.21\n",
      "  Downloading albucore-0.0.21-py3-none-any.whl (12 kB)\n",
      "Collecting eval-type-backport\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_x86_64.whl (57.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cffi>=1.12\n",
      "  Using cached cffi-2.0.0-cp311-cp311-macosx_10_13_x86_64.whl (184 kB)\n",
      "Collecting datasets>=2.0.0\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from evaluate==0.4.3->autotrain-advanced) (0.4.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-macosx_10_9_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: multiprocess in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from evaluate==0.4.3->autotrain-advanced) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from evaluate==0.4.3->autotrain-advanced) (2025.10.0)\n",
      "Collecting starlette<0.42.0,>=0.40.0\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from fastapi==0.115.6->autotrain-advanced) (4.15.0)\n",
      "Collecting anyio\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: certifi in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from httpx==0.28.1->autotrain-advanced) (2025.10.5)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: idna in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from httpx==0.28.1->autotrain-advanced) (3.11)\n",
      "Requirement already satisfied: filelock in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from huggingface-hub==0.27.0->autotrain-advanced) (3.20.0)\n",
      "Collecting click<9.0.0,>=8.1.3\n",
      "  Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapidfuzz<4,>=3\n",
      "  Downloading rapidfuzz-3.14.3-cp311-cp311-macosx_10_9_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from nltk==3.9.1->autotrain-advanced) (2025.11.3)\n",
      "Collecting nvidia-ml-py<12.536.0a0,>=11.450.51\n",
      "  Downloading nvidia_ml_py-12.535.161-py3-none-any.whl (37 kB)\n",
      "Collecting cachetools>=1.0.1\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Collecting termcolor>=1.0.0\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.17.1-py3-none-any.whl (247 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Collecting sqlalchemy>=1.4.2\n",
      "  Downloading sqlalchemy-2.0.44-cp311-cp311-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from pandas==2.2.3->autotrain-advanced) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from pandas==2.2.3->autotrain-advanced) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from pandas==2.2.3->autotrain-advanced) (2025.2)\n",
      "Collecting texttable\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pycryptodomex>=3.16.0\n",
      "  Downloading pycryptodomex-3.23.0-cp37-abi3-macosx_10_9_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyzstd>=0.15.9\n",
      "  Downloading pyzstd-0.18.0-cp311-cp311-macosx_10_9_x86_64.whl (369 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.1/369.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0\n",
      "  Downloading pyppmd-1.1.1-cp311-cp311-macosx_10_9_x86_64.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0\n",
      "  Downloading pybcj-1.0.6-cp311-cp311-macosx_10_9_x86_64.whl (23 kB)\n",
      "Collecting multivolumefile>=0.2.3\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting inflate64<1.1.0,>=1.0.0\n",
      "  Downloading inflate64-1.0.3-cp311-cp311-macosx_10_9_x86_64.whl (35 kB)\n",
      "Collecting brotli>=1.1.0\n",
      "  Downloading brotli-1.2.0-cp311-cp311-macosx_10_9_x86_64.whl (445 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.4/445.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib>=2.1.0\n",
      "  Using cached matplotlib-3.10.7-cp311-cp311-macosx_10_12_x86_64.whl (8.3 MB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests==2.32.3->autotrain-advanced) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests==2.32.3->autotrain-advanced) (2.5.0)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from rouge-score==0.1.2->autotrain-advanced) (1.17.0)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.24.0,>=3.19.6\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.5/427.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from tensorboard==2.18.0->autotrain-advanced) (65.5.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp311-cp311-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-macosx_10_12_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting rich\n",
      "  Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11>=0.8\n",
      "  Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from werkzeug==3.1.3->autotrain-advanced) (3.0.3)\n",
      "Collecting stringzilla>=3.10.4\n",
      "  Downloading stringzilla-4.2.3-cp311-cp311-macosx_10_13_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.6/138.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting simsimd>=5.9.2\n",
      "  Downloading simsimd-6.5.3-cp311-cp311-macosx_10_9_x86_64.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-22.0.0-cp311-cp311-macosx_12_0_x86_64.whl (36.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.0/36.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from datasets[vision]~=3.2.0->autotrain-advanced) (3.13.2)\n",
      "Collecting Mako\n",
      "  Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Using cached pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]~=3.2.0->autotrain-advanced) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]~=3.2.0->autotrain-advanced) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]~=3.2.0->autotrain-advanced) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]~=3.2.0->autotrain-advanced) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]~=3.2.0->autotrain-advanced) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]~=3.2.0->autotrain-advanced) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from aiohttp->datasets[vision]~=3.2.0->autotrain-advanced) (1.22.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-macosx_10_9_x86_64.whl (288 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.60.1-cp311-cp311-macosx_10_9_x86_64.whl (2.4 MB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-macosx_10_9_x86_64.whl (66 kB)\n",
      "Collecting pyparsing>=3\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Collecting numpy<3.0.0,>=1.17\n",
      "  Downloading numpy-2.2.6-cp311-cp311-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting greenlet>=1\n",
      "  Downloading greenlet-3.2.4-cp311-cp311-macosx_11_0_universal2.whl (272 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: sympy in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==1.2.1->autotrain-advanced) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==1.2.1->autotrain-advanced) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==1.2.1->autotrain-advanced) (3.1.6)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from rich->trl==0.13.0->autotrain-advanced) (2.19.2)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate==1.2.1->autotrain-advanced) (1.3.0)\n",
      "Installing collected packages: texttable, simsimd, sentencepiece, nvidia-ml-py, ipadic, brotli, xxhash, werkzeug, tqdm, threadpoolctl, termcolor, tensorboard-data-server, stringzilla, sniffio, requests, rapidfuzz, pyzstd, pyyaml, python-multipart, pyppmd, pyparsing, pydantic-core, pycryptodomex, pycparser, pybcj, pyarrow, protobuf, Pillow, packaging, numpy, multivolumefile, mdurl, markdown, Mako, loguru, kiwisolver, joblib, itsdangerous, inflate64, hf-transfer, h11, grpcio, greenlet, fsspec, fonttools, eval-type-backport, einops, dill, cycler, colorlog, click, cachetools, annotated-types, absl-py, uvicorn, tiktoken, tensorboard, sqlalchemy, scipy, sacremoses, pyngrok, pydantic, py7zr, pandas, opencv-python-headless, nvitop, nltk, markdown-it-py, lightning-utilities, jiwer, huggingface-hub, httpcore, contourpy, cffi, anyio, xgboost, torchvision, torchmetrics, tokenizers, starlette, scikit-learn, rouge-score, rich, matplotlib, httpx, cryptography, alembic, albucore, accelerate, transformers, timm, seqeval, pycocotools, optuna, fastapi, datasets, authlib, albumentations, trl, sentence-transformers, peft, evaluate, autotrain-advanced\n",
      "\u001b[33m  DEPRECATION: ipadic is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for ipadic ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.5\n",
      "    Uninstalling requests-2.32.5:\n",
      "      Successfully uninstalled requests-2.32.5\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.3\n",
      "    Uninstalling PyYAML-6.0.3:\n",
      "      Successfully uninstalled PyYAML-6.0.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.10.0\n",
      "    Uninstalling fsspec-2025.10.0:\n",
      "      Successfully uninstalled fsspec-2025.10.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.4.0\n",
      "    Uninstalling dill-0.4.0:\n",
      "      Successfully uninstalled dill-0.4.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.24\n",
      "    Uninstalling pydantic-1.10.24:\n",
      "      Successfully uninstalled pydantic-1.10.24\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.36.0\n",
      "    Uninstalling huggingface-hub-0.36.0:\n",
      "      Successfully uninstalled huggingface-hub-0.36.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "\u001b[33m  DEPRECATION: rouge-score is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for rouge-score ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.21.0\n",
      "    Uninstalling accelerate-0.21.0:\n",
      "      Successfully uninstalled accelerate-0.21.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.0.dev0\n",
      "    Uninstalling transformers-4.32.0.dev0:\n",
      "      Successfully uninstalled transformers-4.32.0.dev0\n",
      "\u001b[33m  DEPRECATION: seqeval is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for seqeval ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.4.0\n",
      "    Uninstalling peft-0.4.0:\n",
      "      Successfully uninstalled peft-0.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "text-generation 0.6.0 requires pydantic<2.0,>=1.10, but you have pydantic 2.10.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.10 Pillow-11.0.0 absl-py-2.3.1 accelerate-1.2.1 albucore-0.0.21 albumentations-1.4.23 alembic-1.17.1 annotated-types-0.7.0 anyio-4.11.0 authlib-1.4.0 autotrain-advanced-0.8.36 brotli-1.2.0 cachetools-6.2.1 cffi-2.0.0 click-8.3.0 colorlog-6.10.1 contourpy-1.3.3 cryptography-44.0.0 cycler-0.12.1 datasets-3.2.0 dill-0.3.8 einops-0.8.0 eval-type-backport-0.2.2 evaluate-0.4.3 fastapi-0.115.6 fonttools-4.60.1 fsspec-2024.9.0 greenlet-3.2.4 grpcio-1.76.0 h11-0.16.0 hf-transfer-0.1.9 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.27.0 inflate64-1.0.3 ipadic-1.0.0 itsdangerous-2.2.0 jiwer-3.0.5 joblib-1.4.2 kiwisolver-1.4.9 lightning-utilities-0.15.2 loguru-0.7.3 markdown-3.10 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 multivolumefile-0.2.3 nltk-3.9.1 numpy-2.2.6 nvidia-ml-py-12.535.161 nvitop-1.3.2 opencv-python-headless-4.12.0.88 optuna-4.1.0 packaging-24.2 pandas-2.2.3 peft-0.14.0 protobuf-6.33.0 py7zr-0.22.0 pyarrow-22.0.0 pybcj-1.0.6 pycocotools-2.0.8 pycparser-2.23 pycryptodomex-3.23.0 pydantic-2.10.4 pydantic-core-2.27.2 pyngrok-7.2.1 pyparsing-3.2.5 pyppmd-1.1.1 python-multipart-0.0.20 pyyaml-6.0.2 pyzstd-0.18.0 rapidfuzz-3.14.3 requests-2.32.3 rich-14.2.0 rouge-score-0.1.2 sacremoses-0.1.1 scikit-learn-1.6.0 scipy-1.16.3 sentence-transformers-3.3.1 sentencepiece-0.2.0 seqeval-1.2.2 simsimd-6.5.3 sniffio-1.3.1 sqlalchemy-2.0.44 starlette-0.41.3 stringzilla-4.2.3 tensorboard-2.18.0 tensorboard-data-server-0.7.2 termcolor-3.2.0 texttable-1.7.0 threadpoolctl-3.6.0 tiktoken-0.8.0 timm-1.0.12 tokenizers-0.21.4 torchmetrics-1.6.0 torchvision-0.17.2 tqdm-4.67.1 transformers-4.48.0 trl-0.13.0 uvicorn-0.34.0 werkzeug-3.1.3 xgboost-2.1.3 xxhash-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (4.48.0)\n",
      "Requirement already satisfied: peft in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from peft) (2.2.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from peft) (1.2.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: sympy in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (1.2.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: scipy in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from bitsandbytes) (1.16.3)\n",
      "Requirement already satisfied: filelock in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: sympy in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.42.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install autotrain-advanced\n",
    "!pip install transformers peft\n",
    "!pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013b0563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context\n",
      "--- Preparing data for Experiment A (Context-Only) ---\n",
      "--- Preparing data for Experiment A (Context-Only) ---\n",
      "total 2440\n",
      "-rw-r--r--  1 francescodangolo  staff   592K Nov  7 18:01 train.jsonl\n",
      "-rw-r--r--  1 francescodangolo  staff   624K Nov  7 18:01 valid.jsonl\n",
      "total 2440\n",
      "-rw-r--r--  1 francescodangolo  staff   592K Nov  7 18:01 train.jsonl\n",
      "-rw-r--r--  1 francescodangolo  staff   624K Nov  7 18:01 valid.jsonl\n",
      "\n",
      "--- Preparing data for Experiment B (Explain-and-Answer) ---\n",
      "\n",
      "--- Preparing data for Experiment B (Explain-and-Answer) ---\n",
      "total 2688\n",
      "-rw-r--r--  1 francescodangolo  staff   643K Nov  7 18:01 train.jsonl\n",
      "-rw-r--r--  1 francescodangolo  staff   700K Nov  7 18:01 valid.jsonl\n",
      "total 2688\n",
      "-rw-r--r--  1 francescodangolo  staff   643K Nov  7 18:01 train.jsonl\n",
      "-rw-r--r--  1 francescodangolo  staff   700K Nov  7 18:01 valid.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Create the directories for our two experiments\n",
    "%cd /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/\n",
    "!mkdir -p data_context_only\n",
    "!mkdir -p data_exp_ans\n",
    "\n",
    "# Copy and RENAME our prepared files into the structures autotrain expects\n",
    "print(\"--- Preparing data for Experiment A (Context-Only) ---\")\n",
    "!cp data/splits/train_context_only.jsonl data_context_only/train.jsonl\n",
    "!cp data/splits/dev_context_only.jsonl data_context_only/valid.jsonl\n",
    "!ls -lh data_context_only/\n",
    "\n",
    "print(\"\\n--- Preparing data for Experiment B (Explain-and-Answer) ---\")\n",
    "!cp data/splits/train_exp_ans.jsonl data_exp_ans/train.jsonl\n",
    "!cp data/splits/dev_exp_ans.jsonl data_exp_ans/valid.jsonl\n",
    "!ls -lh data_exp_ans/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779707b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in ./venv/lib/python3.11/site-packages (0.27.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.11/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests->huggingface_hub) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edf46c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages/huggingface_hub/_login.py:340\u001b[39m, in \u001b[36mnotebook_login\u001b[39m\u001b[34m(new_session, write_permission)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipywidgets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwidgets\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ipywidgets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mnotebook_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[39m, in \u001b[36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m         message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + custom_message\n\u001b[32m    100\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:31\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     29\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     33\u001b[39m args_msg = [\n\u001b[32m     34\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     36\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/venv/lib/python3.11/site-packages/huggingface_hub/_login.py:343\u001b[39m, in \u001b[36mnotebook_login\u001b[39m\u001b[34m(new_session, write_permission)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `notebook_login` function can only be used in a notebook (Jupyter or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    345\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    346\u001b[39m     )\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_session \u001b[38;5;129;01mand\u001b[39;00m get_token() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mUser is already logged in.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

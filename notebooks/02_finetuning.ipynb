{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b7a7a7cd",
      "metadata": {},
      "source": [
        "# üîß Environment Setup\n",
        "\n",
        "This notebook can run in **both Google Colab and VS Code locally**.\n",
        "\n",
        "**Choose your environment:**\n",
        "- **Google Colab:** Skip to the next cell\n",
        "- **VS Code Local:** Run the cell below first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "14ca5d0a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíª Running locally (VS Code)\n",
            "‚úì Using local path: /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context\n",
            "‚úì Path verified\n"
          ]
        }
      ],
      "source": [
        "# Environment Detection and Setup\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Detect if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"üåê Running in Google Colab\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"üíª Running locally (VS Code)\")\n",
        "\n",
        "# Set base path based on environment\n",
        "if IN_COLAB:\n",
        "    # Colab: Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASE_PATH = \"/content/drive/MyDrive/reproducing_project\"\n",
        "    print(f\"‚úì Drive mounted. Base path: {BASE_PATH}\")\n",
        "else:\n",
        "    # Local: Use project directory\n",
        "    BASE_PATH = \"/Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context\"\n",
        "    print(f\"‚úì Using local path: {BASE_PATH}\")\n",
        "    \n",
        "# Verify path exists\n",
        "if os.path.exists(BASE_PATH):\n",
        "    print(f\"‚úì Path verified\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è WARNING: Path does not exist: {BASE_PATH}\")\n",
        "    print(f\"   Please update BASE_PATH in this cell\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee3fb6ee",
      "metadata": {},
      "source": [
        "# üöÄ Quick Start Guide\n",
        "\n",
        "**Before running:**\n",
        "1. ‚úÖ Upload `data/splits/*.jsonl` files to your Google Drive\n",
        "2. ‚úÖ Set `BASE_PATH` in cell 2 to your Google Drive folder\n",
        "3. ‚úÖ Set `YOUR_HF_USERNAME` in cell 8 to your Hugging Face username\n",
        "4. ‚úÖ Make sure you have a GPU runtime: Runtime > Change runtime type > T4 or A100\n",
        "\n",
        "**Then:** Run all cells (Runtime > Run all)\n",
        "\n",
        "**This notebook trains TWO models:**\n",
        "- Model A: Context-Only approach\n",
        "- Model B: Explain-and-Answer approach\n",
        "\n",
        "**Expected time:** 2-6 hours total (depends on GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "223ca85a",
      "metadata": {
        "id": "223ca85a"
      },
      "source": [
        "# Task 2: Finetuning with Google Colab\n",
        "\n",
        "**Goal:** Reproduce the training from `train.sh` using modern transformers and PEFT libraries.\n",
        "\n",
        "**Two Experiments:**\n",
        "- **Experiment A (Context-Only):** Fine-tune flan-t5-base on `train_context_only.jsonl` / `dev_context_only.jsonl`\n",
        "- **Experiment B (Explain-and-Answer):** Fine-tune flan-t5-base on `train_exp_ans.jsonl` / `dev_exp_ans.jsonl`\n",
        "\n",
        "**Note:** This notebook replaces the outdated `autotrain-advanced` approach with direct use of `transformers` and `peft` libraries, which work reliably in Google Colab.\n",
        "\n",
        "---\n",
        "\n",
        "## Time Tracking (for Reproducibility Log)\n",
        "**Remember to log:**\n",
        "- Start/End time for each experiment\n",
        "- GPU type (Runtime > Change runtime type)\n",
        "- GPU hours used\n",
        "- Any errors or issues encountered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a9d89189",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "a9d89189",
        "outputId": "5f8858f2-8296-4933-f3e0-43da2f50656c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "‚úì All dependencies installed\n",
            "‚úì All dependencies installed\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q transformers datasets peft accelerate bitsandbytes huggingface_hub\n",
        "\n",
        "print(\"‚úì All dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "013b0563",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "013b0563",
        "outputId": "c481c208-23e6-4a74-85f2-90e071317702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Using Local Data ---\n",
            "‚úì Context-Only data: /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/data/splits\n",
            "‚úì Explain-and-Answer data: /Users/francescodangolo/Desktop/CS 421 - Natural Language Processing/Research Project/qa-with-conflicting-context/data/splits\n",
            "  ‚úì train_context_only.jsonl (591.8 KB)\n",
            "  ‚úì dev_context_only.jsonl (624.4 KB)\n",
            "  ‚úì train_exp_ans.jsonl (642.6 KB)\n",
            "  ‚úì dev_exp_ans.jsonl (699.8 KB)\n",
            "\n",
            "‚úì Data preparation complete\n"
          ]
        }
      ],
      "source": [
        "# Prepare data directories for both experiments\n",
        "import os\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Colab: Create directories and copy from Drive\n",
        "    data_context_dir = f\"{BASE_PATH}/data_context_only\"\n",
        "    data_exp_ans_dir = f\"{BASE_PATH}/data_exp_ans\"\n",
        "    \n",
        "    os.makedirs(data_context_dir, exist_ok=True)\n",
        "    os.makedirs(data_exp_ans_dir, exist_ok=True)\n",
        "    \n",
        "    print(\"--- Preparing Experiment A (Context-Only) ---\")\n",
        "    !cp \"{BASE_PATH}/data/splits/train_context_only.jsonl\" \"{data_context_dir}/train.jsonl\"\n",
        "    !cp \"{BASE_PATH}/data/splits/dev_context_only.jsonl\" \"{data_context_dir}/valid.jsonl\"\n",
        "    !ls -lh \"{data_context_dir}/\"\n",
        "    \n",
        "    print(\"\\n--- Preparing Experiment B (Explain-and-Answer) ---\")\n",
        "    !cp \"{BASE_PATH}/data/splits/train_exp_ans.jsonl\" \"{data_exp_ans_dir}/train.jsonl\"\n",
        "    !cp \"{BASE_PATH}/data/splits/dev_exp_ans.jsonl\" \"{data_exp_ans_dir}/valid.jsonl\"\n",
        "    !ls -lh \"{data_exp_ans_dir}/\"\n",
        "else:\n",
        "    # Local: Use existing data/splits directory directly\n",
        "    data_context_dir = f\"{BASE_PATH}/data/splits\"\n",
        "    data_exp_ans_dir = f\"{BASE_PATH}/data/splits\"\n",
        "    \n",
        "    print(\"--- Using Local Data ---\")\n",
        "    print(f\"‚úì Context-Only data: {data_context_dir}\")\n",
        "    print(f\"‚úì Explain-and-Answer data: {data_exp_ans_dir}\")\n",
        "    \n",
        "    # Verify files exist\n",
        "    required_files = [\n",
        "        'train_context_only.jsonl', 'dev_context_only.jsonl',\n",
        "        'train_exp_ans.jsonl', 'dev_exp_ans.jsonl'\n",
        "    ]\n",
        "    \n",
        "    for file in required_files:\n",
        "        path = os.path.join(data_context_dir, file)\n",
        "        if os.path.exists(path):\n",
        "            size = os.path.getsize(path) / 1024  # KB\n",
        "            print(f\"  ‚úì {file} ({size:.1f} KB)\")\n",
        "        else:\n",
        "            print(f\"  ‚úó {file} NOT FOUND\")\n",
        "\n",
        "print(\"\\n‚úì Data preparation complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6edf46c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "9bc60a77c0b54941b6b8e93f4182beb5",
            "0e572671a2954dcdbfb21f946896802f",
            "b62777a4a37b4cfebb5d24589efddaae",
            "939039d79aa4429da8c312498c1db7f3",
            "76ad8bc9144b42678c2a9bb2b61d31ff",
            "44a87a29d48841b3be880f00044d43ac",
            "83ab261bdfac452fab90372d84cae0f9",
            "ba4e29636d81479f836696cbafd8c82f",
            "10c2d01fed304e329cabc2d651209aa1",
            "e12dc0a5fb5c49ae869065c188a836ae",
            "61b44c8669a14a44b92bfcc184e9dcfc",
            "1cf86e2736ad4ac1bee0ac0a56157c27",
            "630d05cdb1774f69b096ef43b782123f",
            "93af27a6c5414b48a26031f0fe7a19e4",
            "f798027b38864e52991047dad0968ee9",
            "70601af4229442d180cca12c886315ac",
            "ba367eb535684e28bd924795a448bc2c",
            "d2924443cb864cc0880db54340156339",
            "9d05477583ef4557823d1557e4a694b9",
            "7e6ea9120ef4499e916b28acd177a3a5"
          ]
        },
        "id": "6edf46c1",
        "outputId": "f9844673-e1fe-4171-bf2e-de8d05db838a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîê Authenticating with Hugging Face (Local)...\n",
            "\n",
            "‚ö†Ô∏è  IMPORTANT: You need to authenticate first!\n",
            "\n",
            "Option 1 (Recommended): Run this in terminal:\n",
            "   huggingface-cli login\n",
            "\n",
            "Option 2: Set environment variable:\n",
            "   export HF_TOKEN='your_token_here'\n",
            "\n",
            "After authentication, this cell will verify the login.\n",
            "\n",
            "============================================================\n",
            "‚úÖ Already authenticated! Token found.\n",
            "\n",
            "‚úì Authenticated as: dangolofrancesco\n",
            "‚úì Ready to train and push models!\n",
            "\n",
            "‚úì Authenticated as: dangolofrancesco\n",
            "‚úì Ready to train and push models!\n"
          ]
        }
      ],
      "source": [
        "# Hugging Face Authentication (environment-aware)\n",
        "import os\n",
        "\n",
        "# Set your Hugging Face username here\n",
        "HF_USERNAME = \"dangolofrancesco\"  # ‚ö†Ô∏è UPDATE THIS to your HF username\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Colab: Use notebook_login with widget\n",
        "    from huggingface_hub import notebook_login\n",
        "    print(\"üîê Please authenticate with Hugging Face (Colab):\")\n",
        "    notebook_login()\n",
        "else:\n",
        "    # Local: Use CLI-based authentication\n",
        "    print(\"üîê Authenticating with Hugging Face (Local)...\")\n",
        "    print(\"\\n‚ö†Ô∏è  IMPORTANT: You need to authenticate first!\")\n",
        "    print(\"\\nOption 1 (Recommended): Run this in terminal:\")\n",
        "    print(\"   huggingface-cli login\")\n",
        "    print(\"\\nOption 2: Set environment variable:\")\n",
        "    print(\"   export HF_TOKEN='your_token_here'\")\n",
        "    print(\"\\nAfter authentication, this cell will verify the login.\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    \n",
        "    # Check if authenticated by trying to import and verify\n",
        "    from huggingface_hub import HfFolder\n",
        "    token = HfFolder.get_token()\n",
        "    \n",
        "    if token:\n",
        "        print(\"‚úÖ Already authenticated! Token found.\")\n",
        "        from huggingface_hub import login\n",
        "        login(token=token)\n",
        "    else:\n",
        "        print(\"\\n‚ùå Not authenticated yet!\")\n",
        "        print(\"\\nPlease run in terminal: huggingface-cli login\")\n",
        "        print(\"Then re-run this cell.\")\n",
        "        raise ValueError(\"Hugging Face authentication required. Run 'huggingface-cli login' in terminal.\")\n",
        "\n",
        "print(f\"\\n‚úì Authenticated as: {HF_USERNAME}\")\n",
        "print(\"‚úì Ready to train and push models!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qm1iOaqKEg02",
      "metadata": {
        "id": "qm1iOaqKEg02"
      },
      "outputs": [],
      "source": [
        "# Training function that matches train.sh configuration\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "def train_model(experiment_name, data_path, model_name_suffix, your_hf_username, train_file, valid_file):\n",
        "    \"\"\"\n",
        "    Train a model matching the train.sh configuration.\n",
        "\n",
        "    Args:\n",
        "        experiment_name: \"Context-Only\" or \"Explain-and-Answer\"\n",
        "        data_path: Path to training data directory\n",
        "        model_name_suffix: Suffix for model name (e.g., \"context-only\")\n",
        "        your_hf_username: Your Hugging Face username\n",
        "        train_file: Name of training file (e.g., \"train_context_only.jsonl\")\n",
        "        valid_file: Name of validation file (e.g., \"dev_context_only.jsonl\")\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  EXPERIMENT: {experiment_name}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    start_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"‚è±Ô∏è  Start Time: {start_datetime}\")\n",
        "\n",
        "    # Configuration (matching train.sh)\n",
        "    base_model_id = \"google/flan-t5-base\"\n",
        "    new_model_repo = f\"{your_hf_username}/flan-t5-{model_name_suffix}\"\n",
        "\n",
        "    # LoRA Config (from train.sh: use-peft with default LoRA settings)\n",
        "    peft_config = LoraConfig(\n",
        "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "        r=16,              # LoRA rank\n",
        "        lora_alpha=32,     # LoRA alpha\n",
        "        lora_dropout=0.05, # LoRA dropout\n",
        "        target_modules=[\"q\", \"v\"],  # Target attention layers explicitly\n",
        "        inference_mode=False\n",
        "    )\n",
        "\n",
        "    # Training Args (matching train.sh parameters)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"{BASE_PATH}/models/{model_name_suffix}\",\n",
        "        learning_rate=2e-4,                    # from train.sh\n",
        "        per_device_train_batch_size=4,         # from train.sh\n",
        "        per_device_eval_batch_size=4,\n",
        "        num_train_epochs=3,                    # from train.sh\n",
        "        logging_steps=10,\n",
        "        save_strategy=\"epoch\",\n",
        "        eval_strategy=\"epoch\",                 # Changed from evaluation_strategy (deprecated)\n",
        "        load_best_model_at_end=True,\n",
        "        push_to_hub=True,\n",
        "        hub_model_id=new_model_repo,\n",
        "        report_to=\"none\",  # Disable wandb/tensorboard\n",
        "        warmup_steps=50,  # Add warmup\n",
        "        weight_decay=0.01,  # Add weight decay\n",
        "        logging_first_step=True,  # Log first step to see if training starts\n",
        "        save_total_limit=2,  # Only keep 2 checkpoints\n",
        "    )\n",
        "\n",
        "    print(f\"üì¶ Loading dataset from: {data_path}\")\n",
        "    \n",
        "    # Determine file paths based on environment\n",
        "    if IN_COLAB:\n",
        "        train_path = os.path.join(data_path, 'train.jsonl')\n",
        "        valid_path = os.path.join(data_path, 'valid.jsonl')\n",
        "    else:\n",
        "        # Local: use original filenames\n",
        "        train_path = os.path.join(data_path, train_file)\n",
        "        valid_path = os.path.join(data_path, valid_file)\n",
        "    \n",
        "    # Load dataset\n",
        "    raw_datasets = load_dataset('json', data_files={\n",
        "        'train': train_path,\n",
        "        'validation': valid_path\n",
        "    })\n",
        "\n",
        "    print(f\"   - Training examples: {len(raw_datasets['train'])}\")\n",
        "    print(f\"   - Validation examples: {len(raw_datasets['validation'])}\")\n",
        "\n",
        "    print(f\"\\nü§ñ Loading model and tokenizer: {base_model_id}\")\n",
        "    # Load model and tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(base_model_id)\n",
        "\n",
        "    # Preprocessing function (matching train.sh: model_max_length=1024)\n",
        "    def preprocess_function(examples):\n",
        "        # Ensure inputs are strings (handle potential None or non-string values)\n",
        "        inputs = [str(text) if text is not None else \"\" for text in examples['input']]\n",
        "        outputs = [str(text) if text is not None else \"\" for text in examples['output']]\n",
        "        \n",
        "        model_inputs = tokenizer(\n",
        "            inputs, \n",
        "            max_length=1024,  # from train.sh\n",
        "            truncation=True,\n",
        "            padding=False  # Will pad dynamically\n",
        "        )\n",
        "        \n",
        "        # Tokenize targets - T5 requires this format\n",
        "        labels = tokenizer(\n",
        "            text_target=outputs,  # Use text_target parameter for T5\n",
        "            max_length=256,\n",
        "            truncation=True,\n",
        "            padding=False\n",
        "        )\n",
        "        \n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    print(\"üîÑ Tokenizing dataset...\")\n",
        "    tokenized_datasets = raw_datasets.map(\n",
        "        preprocess_function,\n",
        "        batched=True,\n",
        "        remove_columns=raw_datasets[\"train\"].column_names\n",
        "    )\n",
        "    \n",
        "    # Debug: Check tokenized data\n",
        "    print(f\"   Sample input IDs length: {len(tokenized_datasets['train'][0]['input_ids'])}\")\n",
        "    print(f\"   Sample labels length: {len(tokenized_datasets['train'][0]['labels'])}\")\n",
        "    print(f\"   First few input tokens: {tokenized_datasets['train'][0]['input_ids'][:10]}\")\n",
        "    print(f\"   First few label tokens: {tokenized_datasets['train'][0]['labels'][:10]}\")\n",
        "\n",
        "    print(\"üîß Applying LoRA (PEFT)...\")\n",
        "    # Apply LoRA\n",
        "    model = get_peft_model(model, peft_config)\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    # Ensure model is in training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Enable gradient checkpointing for memory efficiency\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "    # Data collator for dynamic padding (with label padding)\n",
        "    data_collator = DataCollatorForSeq2Seq(\n",
        "        tokenizer=tokenizer,\n",
        "        model=model,\n",
        "        padding=True,\n",
        "        label_pad_token_id=-100  # Ignore padding tokens in loss\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    print(f\"\\nüöÄ Starting training for: {experiment_name}\")\n",
        "    print(f\"   Model will be saved to: {new_model_repo}\")\n",
        "\n",
        "    # Train\n",
        "    trainer.train()\n",
        "\n",
        "    print(f\"\\nüíæ Pushing model to Hugging Face Hub: {new_model_repo}\")\n",
        "    # Push to hub\n",
        "    trainer.push_to_hub()\n",
        "\n",
        "    # Calculate time\n",
        "    end_time = time.time()\n",
        "    end_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    duration_seconds = end_time - start_time\n",
        "    duration_hours = duration_seconds / 3600\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  ‚úÖ EXPERIMENT COMPLETE: {experiment_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"‚è±Ô∏è  End Time: {end_datetime}\")\n",
        "    print(f\"‚è±Ô∏è  Duration: {duration_hours:.2f} hours ({duration_seconds/60:.1f} minutes)\")\n",
        "    print(f\"üîó Model Hub: https://huggingface.co/{new_model_repo}\")\n",
        "    print(f\"\\nüìù LOG THIS IN REPRODUCIBILITY_LOG.md:\")\n",
        "    print(f\"   - Experiment: {experiment_name}\")\n",
        "    print(f\"   - Start: {start_datetime}\")\n",
        "    print(f\"   - End: {end_datetime}\")\n",
        "    print(f\"   - GPU Hours: {duration_hours:.2f}\")\n",
        "    print(f\"   - Model: {new_model_repo}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return trainer, duration_hours\n",
        "\n",
        "print(\"‚úì Training function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b243cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up data paths for experiments (using variables from data preparation cell)\n",
        "context_only_path = data_context_dir\n",
        "exp_ans_path = data_exp_ans_dir\n",
        "\n",
        "print(f\"‚úì Experiment A data path: {context_only_path}\")\n",
        "print(f\"‚úì Experiment B data path: {exp_ans_path}\")\n",
        "print(f\"‚úì Hugging Face username: {HF_USERNAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc490a8f",
      "metadata": {},
      "source": [
        "---\n",
        "## üî¨ Experiment A: Context-Only\n",
        "\n",
        "Fine-tune on prompts that include only the conflicting contexts (no explanation requested)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d383b420",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# EXPERIMENT A: Context-Only\n",
        "# ============================================================================\n",
        "# This experiment trains on questions with only the context (no explanations)\n",
        "\n",
        "trainer_a, duration_a = train_model(\n",
        "    experiment_name=\"Context-Only (Experiment A)\",\n",
        "    data_path=context_only_path,  # Uses environment-aware path from earlier cell\n",
        "    model_name_suffix=\"context-only\",\n",
        "    your_hf_username=HF_USERNAME,\n",
        "    train_file=\"train_context_only.jsonl\",\n",
        "    valid_file=\"dev_context_only.jsonl\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37c807dc",
      "metadata": {},
      "source": [
        "---\n",
        "## üî¨ Experiment B: Explain-and-Answer\n",
        "\n",
        "Fine-tune on prompts that ask the model to explain the conflict AND provide an answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e871309",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# EXPERIMENT B: Explain-and-Answer\n",
        "# ============================================================================\n",
        "# This experiment trains on questions with explanations before the answer\n",
        "\n",
        "trainer_b, duration_b = train_model(\n",
        "    experiment_name=\"Explain-and-Answer (Experiment B)\",\n",
        "    data_path=exp_ans_path,  # Uses environment-aware path from earlier cell\n",
        "    model_name_suffix=\"exp-ans\",\n",
        "    your_hf_username=HF_USERNAME,\n",
        "    train_file=\"train_exp_ans.jsonl\",\n",
        "    valid_file=\"dev_exp_ans.jsonl\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49dd7b75",
      "metadata": {},
      "source": [
        "---\n",
        "## üìä Summary\n",
        "\n",
        "Total GPU hours and summary of both experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26d3dcbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" üéâ ALL EXPERIMENTS COMPLETED!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nüìä TOTAL GPU HOURS: {duration_a + duration_b:.2f} hours\")\n",
        "print(f\"\\n   Experiment A (Context-Only): {duration_a:.2f} hours\")\n",
        "print(f\"   Experiment B (Explain-and-Answer): {duration_b:.2f} hours\")\n",
        "print(f\"\\nüîó MODELS:\")\n",
        "print(f\"   - https://huggingface.co/{HF_USERNAME}/flan-t5-context-only\")\n",
        "print(f\"   - https://huggingface.co/{HF_USERNAME}/flan-t5-exp-ans\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"\\nüìù NEXT STEPS:\")\n",
        "print(\"   1. Update REPRODUCIBILITY_LOG.md with the GPU hours above\")\n",
        "print(\"   2. Run evaluation on test sets\")\n",
        "print(\"   3. Document any issues encountered\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e572671a2954dcdbfb21f946896802f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba4e29636d81479f836696cbafd8c82f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_10c2d01fed304e329cabc2d651209aa1",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "10c2d01fed304e329cabc2d651209aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf86e2736ad4ac1bee0ac0a56157c27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a87a29d48841b3be880f00044d43ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70601af4229442d180cca12c886315ac",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ba367eb535684e28bd924795a448bc2c",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "61b44c8669a14a44b92bfcc184e9dcfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "630d05cdb1774f69b096ef43b782123f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70601af4229442d180cca12c886315ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ad8bc9144b42678c2a9bb2b61d31ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_93af27a6c5414b48a26031f0fe7a19e4",
            "style": "IPY_MODEL_f798027b38864e52991047dad0968ee9",
            "tooltip": ""
          }
        },
        "7e6ea9120ef4499e916b28acd177a3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83ab261bdfac452fab90372d84cae0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "939039d79aa4429da8c312498c1db7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_1cf86e2736ad4ac1bee0ac0a56157c27",
            "style": "IPY_MODEL_630d05cdb1774f69b096ef43b782123f",
            "value": true
          }
        },
        "93af27a6c5414b48a26031f0fe7a19e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc60a77c0b54941b6b8e93f4182beb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_83ab261bdfac452fab90372d84cae0f9"
          }
        },
        "9d05477583ef4557823d1557e4a694b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b62777a4a37b4cfebb5d24589efddaae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e12dc0a5fb5c49ae869065c188a836ae",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_61b44c8669a14a44b92bfcc184e9dcfc",
            "value": ""
          }
        },
        "ba367eb535684e28bd924795a448bc2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba4e29636d81479f836696cbafd8c82f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2924443cb864cc0880db54340156339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d05477583ef4557823d1557e4a694b9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7e6ea9120ef4499e916b28acd177a3a5",
            "value": "Connecting..."
          }
        },
        "e12dc0a5fb5c49ae869065c188a836ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f798027b38864e52991047dad0968ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
